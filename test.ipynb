{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import psycopg2\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Load data locally\n",
    "df = pd.read_csv(\"/mnt/data/marketing_campaign_dataset.csv\")\n",
    "\n",
    "# 1. Load Data into MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"retail_db\"]\n",
    "collection = db[\"marketing_campaign\"]\n",
    "\n",
    "# Convert DataFrame to dictionary records and insert into MongoDB\n",
    "collection.insert_many(df.to_dict(orient=\"records\"))\n",
    "print(\"Data successfully inserted into MongoDB!\")\n",
    "\n",
    "# 2. Define PostgreSQL Schema\n",
    "postgres_conn = psycopg2.connect(\n",
    "    dbname=\"retail_db\", user=\"admin\", password=\"password\", host=\"localhost\"\n",
    ")\n",
    "cursor = postgres_conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS marketing_campaign (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        customer_id INT,\n",
    "        product_category VARCHAR(255),\n",
    "        amount_spent DECIMAL,\n",
    "        rating DECIMAL,\n",
    "        purchase_date DATE\n",
    "    );\n",
    "\"\"\")\n",
    "postgres_conn.commit()\n",
    "\n",
    "# 3. Transfer Data from MongoDB to PostgreSQL\n",
    "records = collection.find({}, {\"_id\": 0})\n",
    "for record in records:\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO marketing_campaign (customer_id, product_category, amount_spent, rating, purchase_date) VALUES (%s, %s, %s, %s, %s)\",\n",
    "        (record[\"customer_id\"], record[\"product_category\"], record[\"amount_spent\"], record[\"rating\"], record[\"purchase_date\"])\n",
    "    )\n",
    "postgres_conn.commit()\n",
    "cursor.close()\n",
    "postgres_conn.close()\n",
    "print(\"Data successfully transferred to PostgreSQL!\")\n",
    "\n",
    "# 4. Spark SQL Analysis\n",
    "spark = SparkSession.builder.appName(\"RetailAnalysis\").getOrCreate()\n",
    "df_spark = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/retail_db\") \\\n",
    "    .option(\"dbtable\", \"marketing_campaign\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()\n",
    "\n",
    "df_spark.createOrReplaceTempView(\"marketing_campaign\")\n",
    "\n",
    "# Example queries\n",
    "df_spark.sql(\"SELECT product_category, COUNT(*) as purchases FROM marketing_campaign GROUP BY product_category ORDER BY purchases DESC\").show()\n",
    "df_spark.sql(\"SELECT customer_id, SUM(amount_spent) as total_spent FROM marketing_campaign GROUP BY customer_id ORDER BY total_spent DESC LIMIT 5\").show()\n",
    "\n",
    "# Export to Parquet\n",
    "df_spark.write.parquet(\"/mnt/data/marketing_campaign.parquet\")\n",
    "print(\"Data exported to Parquet!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
